# 图解深度学习

## 第一章 绪论

### 1.1 深度学习与机器学习

* 深度学习是一种机器学习方法，根据输入数据进行分类或递归。
* 机器学习可用于自然语言处理、图像识别、生物信息学以及风险预测等。
* 机器学习是一种统计学习方法，需要使用大量数据进行学习
  * 有监督学习。需要输入及期望输出。
  * 无监督学习。无期望值输出。
* 深度学习是一个多层网络结果，和人脑的认知结构相似。

### 1.2 深度学习的发展过程

* 2011年语音识别领域，基准测试中达到顶级。
* 图像识别领域，深度学习打破原有方法的性能堡垒，有效性得到确定。
* Google提出自动学习方法。
* Dropout等防止过拟合的方法、激活函数、预训练。
* 英伟达GPU的支持。

### 1.3 为什么是深度学习

* 深度学习在各个领域打破了原有的性能极限，取得了令人瞩目的成绩。
* 模仿人脑机制获取知识。
* 无需人为选择，能够自动学习提取什么样的特征。

### 1.4 什么是深度学习

* 深度学习一般是指具有多层结构的网络，层数没有严格定义。
* 深度学习的起源包括感知机和玻尔兹曼机。
* 在多层感知机的基础上加入类似人类视觉皮质的结构而得到卷积神经网络。
* 什么都玻尔兹曼机以及深度学习网络是通过把多个受限玻尔兹曼机组合到一起得到的。
* 感知机的深度学习是有监督学习。
* 玻尔兹曼机的深度学习是无监督学习。

### 1.5 本书结构

---
## 第二章 神经网络

### 2.1 神经网络的历史

* 深度学习是基于神经网络发展起来的。
* 神经网络三个阶段
  * 1940 - 1970 第一阶段
    * 1943年，Warren McCulloch和Walter Pitts提出了形式神经元模型。被称为M-P模型。
    * 1958年，Roseblatt提出感知机。神经网络研究迎来了第一次热潮。
    * 1969年，Minsky等人指出感知机无法解决线性不可分问题，神经网络研究陷入了低潮。
  * 1980 - 1990 第二阶段
    * 福岛等人提出了神经认知机。
    * 霍普菲尔德提出了Hopfield Mode。
    * Rumelhart等人提出了误差反向传播算法，解决了线性不可分问题。
    * Lecun等人提出了卷积神经网络。
  * 2000 - 2010 第三阶段
    * Hinton和Bengio提出了预训练和深度神经网络相结合。
    * Frank Seide语音识别获得压倒性优势。
    * Krizhevsky提出在卷积神经网络中引入ReLU作为激活函数，在图像识别中获得了压倒性的优势。

### 2.2 M-P模型

* M-P模型是首个通过模仿神经元而形成的模型。
* 可以表示AND和OR等逻辑运算。

### 2.3 感知机

### 2.4 多层感知机

---